{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Various Analyses</h1>\n",
    "\n",
    "Trying different analyses on Decision Trees, Random Forests, and K-Fold Cross Validation through changing of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # Iris dataset\n",
    "from sklearn.model_selection import KFold # K-fold Cross Validation\n",
    "from sklearn import tree # Decision Tree\n",
    "from sklearn import ensemble # Random forest\n",
    "from sklearn import metrics # Accuracy scores\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Helper Functions</h2>\n",
    "\n",
    "Function for obtaining data splits over k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSets(k, data, targets):\n",
    "    kFold = KFold(k, True, 1)\n",
    "\n",
    "    # Data sets\n",
    "    trainSets = []\n",
    "    testSets = []\n",
    "    # Target sets\n",
    "    trainTargs = []\n",
    "    testTargs = []\n",
    "    \n",
    "    for train, test in kFold.split(data):\n",
    "        # Training values\n",
    "        trainSets.append( [data[i] for i in train] )\n",
    "        trainTargs.append( [targets[i] for i in train] )\n",
    "\n",
    "        # Testing values\n",
    "        testSets.append( [data[i] for i in test] )\n",
    "        testTargs.append( [targets[i] for i in test] )\n",
    "        \n",
    "    return trainSets, testSets, trainTargs, testTargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for printing out accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printScores(scores):\n",
    "    # Results\n",
    "    for score in scores:\n",
    "        print(\"Accuracy: {0:0.4f}\".format(score))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for plotting results / scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScores(scores, xL, yL, t):\n",
    "    n = len(scores)\n",
    "    x = np.linspace(0, n, num = n)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    p1 = fig.add_subplot()\n",
    "    # It's the holidays\n",
    "    p1.plot(x, scores,\n",
    "             color = \"forestgreen\",\n",
    "             marker = \"*\",\n",
    "             markersize = \"10\",\n",
    "             markeredgecolor = \"indianred\",\n",
    "             markerfacecolor = \"indianred\",)\n",
    "    p1.set_xlabel(xL)\n",
    "    p1.set_ylabel(yL)\n",
    "    p1.set_title(t)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for finding Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVariance(predictions):\n",
    "    return np.mean((predictions - np.mean(predictions))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for finding Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBias(predictions, target):\n",
    "    truth = np.mean(target)\n",
    "    return np.mean(predictions) - truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for finding Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMSE(predictions, target):\n",
    "    truth = np.mean(target)\n",
    "    return np.mean((predictions-truth)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris Dataset\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Quality Dataset\n",
    "df = pd.read_csv('WineQuality/winequality-white.csv', delimiter=';')\n",
    "\n",
    "wines = df.drop(columns='quality')\n",
    "wines = wines.to_numpy()\n",
    "\n",
    "targets = df['quality']\n",
    "targets = targets.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Trees</h1>\n",
    "\n",
    "Analysis on how the maximum depth (`max_depth`) of a tree affects model accuracy and execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run a Decision Tree with max_depth n over k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDecisionTree(k, data, targets, n):\n",
    "    accuracy = []\n",
    "    squareErrors = []\n",
    "    variances = []\n",
    "    biases= []\n",
    "    trainS, testS, trainT, testT = getSets(k, data, targets)\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        classTree = tree.DecisionTreeClassifier(max_depth = n)\n",
    "        # Training\n",
    "        classTree = classTree.fit(trainS[i], trainT[i])\n",
    "        # Testing\n",
    "        test = classTree.predict(testS[i])\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy.append(metrics.accuracy_score(testT[i], test))\n",
    "        # Variances\n",
    "        variances.append(getVariance(test))\n",
    "        # Biases\n",
    "        biases.append(getBias(test, testT[i]))\n",
    "        # Mean Square Error\n",
    "        squareErrors.append(getMSE(test, testT[i]))\n",
    "        \n",
    "    # Mean results\n",
    "    data = {\n",
    "        \"accuracy\": np.mean(accuracy),\n",
    "        \"bias\": np.mean(biases),\n",
    "        \"variance\": np.mean(variances),\n",
    "        \"mse\": np.mean(squareErrors)\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run decision trees with max_depths within the range (start, end), over k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTreeDepths(k, start, end, data, targets):\n",
    "    allData = []\n",
    "    for i in range(start, end):\n",
    "        allData.append(runDecisionTree(k, data, targets, i))\n",
    "    \n",
    "    return allData        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Iris Flowers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9199999999999999,\n",
       " 'bias': -2.2204460492503132e-17,\n",
       " 'variance': 0.6511111111111111,\n",
       " 'mse': 0.6542222222222223}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree on 5 Folds\n",
    "runDecisionTree(5, iris.data, iris.target, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decision Trees from 2 to 10 folds\n",
    "irisTrees = []\n",
    "for i in range(2, 10):\n",
    "    irisTrees.append(runDecisionTree(i, iris.data, iris.target, i))\n",
    "\n",
    "xAxis = \"number of k-folds\"\n",
    "yAxis = \"mean accuracy\"\n",
    "title = \"Mean Accuracy for Multiple K-fold Cross Validations\"\n",
    "# plotScores(irisTrees, xAxis, yAxis, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Wine Quality</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.43670821954931105,\n",
       " 'bias': 0.008505555439744761,\n",
       " 'variance': 0.04907719932682346,\n",
       " 'mse': 0.10690255438948444}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Decision Tree on 5 folds\n",
    "runDecisionTree(5, wines, targets, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decison Trees from 2 to 10 folds\n",
    "wineTrees = []\n",
    "for i in range(2, 10):\n",
    "    wineTrees.append(runDecisionTree(i, wines, targets, i))\n",
    "    \n",
    "xAxis = \"number of k-folds\"\n",
    "yAxis = \"mean accuracy\"\n",
    "title = \"Mean Accuracy for Multiple K-fold Cross Validations\"\n",
    "# plotScores(wineTrees, xAxis, yAxis, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>\n",
    "\n",
    "Analysis on how the number of trees (`n_estimators`) in a forest effects model accuracy and execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run a Random Forest over k-folds with n trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runRandomForest(k, n, data, targets, d):\n",
    "    accuracy = []\n",
    "    squareErrors = []\n",
    "    variances = []\n",
    "    biases= []\n",
    "    trainS, testS, trainT, testT = getSets(k, data, targets)\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        forest = ensemble.RandomForestClassifier(n_estimators = n, max_depth = d)\n",
    "        # Training\n",
    "        forest = forest.fit(trainS[i], trainT[i])\n",
    "        # Testing\n",
    "        test = forest.predict(testS[i])\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy.append(metrics.accuracy_score(testT[i], test))\n",
    "        # Variances\n",
    "        variances.append(getVariance(test))\n",
    "        # Biases\n",
    "        biases.append(getBias(test, testT[i]))\n",
    "        # Mean Square Error\n",
    "        squareErrors.append(getMSE(test, testT[i]))\n",
    "        \n",
    "    # Mean results\n",
    "    data = {\n",
    "        \"accuracy\": np.mean(accuracy),\n",
    "        \"bias\": np.mean(biases),\n",
    "        \"variance\": np.mean(variances),\n",
    "        \"mse\": np.mean(squareErrors)\n",
    "    }\n",
    "    \n",
    "    # Printing results\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run Random Forests of range(start, end) trees with max_depth d over k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runForestNums(k, start, end, data, targets, d):\n",
    "    allData = []\n",
    "    for i in range(start, end):\n",
    "        allData.append(runRandomForest(k, i, data, targets, d))\n",
    "        \n",
    "    return allData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Iris Flowers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8,\n",
       " 'bias': -0.053333333333333344,\n",
       " 'variance': 0.5880000000000001,\n",
       " 'mse': 0.6453333333333333}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest on 5 folds with 10 trees\n",
    "runRandomForest(5, 10, iris.data, iris.target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest on 5 folds with 10 to 20 trees\n",
    "irisForestsTree = []\n",
    "for i in range(10, 20):\n",
    "    irisForestsTree.append(runRandomForest(5, i, iris.data, iris.target, i))\n",
    "    \n",
    "xAxis = \"number of k-folds\"\n",
    "yAxis = \"mean accuracy\"\n",
    "title = \"Mean Accuracy for Varying Tree Counts\"\n",
    "# plotScores(irisForestsTree, xAxis, yAxis, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Wine Quality</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.448761334973213,\n",
       " 'bias': 0.12209084655312577,\n",
       " 'variance': 0.0,\n",
       " 'mse': 0.015361395361437805}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest on 5 folds with 10 trees\n",
    "runRandomForest(5, 10, wines, targets, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest on 5 folds with 10 to 20 trees\n",
    "wineForestsTree = []\n",
    "startTime = time.time() # Timer start\n",
    "\n",
    "for i in range(10, 20):\n",
    "    wineForestsTree.append(runRandomForest(5, i, wines, targets, i))\n",
    "    \n",
    "totalTime = time.time() - startTime # Timer end\n",
    "    \n",
    "xAxis = \"number of k-folds\"\n",
    "yAxis = \"mean accuracy\"\n",
    "title = \"Mean Accuracy for Varying Tree Counts\"\n",
    "# plotScores(wineForestsTree, xAxis, yAxis, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K-Fold Cross Validation</h1>\n",
    "\n",
    "Analysis on how number of folds (`k`) affects the validation of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Iris Flowers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n"
     ]
    }
   ],
   "source": [
    "print('h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Wine Quality</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hh\n"
     ]
    }
   ],
   "source": [
    "print('hh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
