{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iris Dataset ML Exercises**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # Iris dataset\n",
    "from sklearn.model_selection import KFold # K-fold Cross Validation\n",
    "from sklearn import tree # Decision Tree\n",
    "from sklearn import ensemble # Random forest\n",
    "from sklearn import metrics # Accuracy scores\n",
    "\n",
    "import graphviz\n",
    "\n",
    "# Load in our dataset\n",
    "irisData = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Tree Model</h1>\n",
    "\n",
    "Initial experimentation on Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree initialization\n",
    "classTree = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Decision tree training (induction + pruning)\n",
    "classTree = classTree.fit(irisData.data, irisData.target)\n",
    "\n",
    "# Decision tree visualization\n",
    "dotData = tree.export_graphviz(classTree, out_file = None, \n",
    "                     feature_names = irisData.feature_names,  \n",
    "                     class_names = irisData.target_names,  \n",
    "                     filled = True, rounded = True,  \n",
    "                     special_characters = True)  \n",
    "# graph = graphviz.Source(dotData)  \n",
    "# graph.render(\"Iris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Tree Model with 5-fold Cross Validation</h1>\n",
    "\n",
    "Wrapping decision trees work with K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation parameters\n",
    "k = 5\n",
    "kFold = KFold(k, True, 1)\n",
    "\n",
    "# Collected scores\n",
    "allScores = []\n",
    "\n",
    "# Needed datasets\n",
    "trainSets = []\n",
    "testSets = []\n",
    "trainTargets = []\n",
    "testTargets = []\n",
    "\n",
    "for train, test in kFold.split(irisData.data):\n",
    "    # Training values\n",
    "    trainingSet = [irisData.data[i] for i in train] \n",
    "    trainSets.append(trainingSet)\n",
    "    trainingTargs = [irisData.target[i] for i in train] \n",
    "    trainTargets.append(trainingTargs)\n",
    "    \n",
    "    # Testing values\n",
    "    testingSet = [irisData.data[i] for i in test] \n",
    "    testSets.append(testingSet)\n",
    "    testingTargs = [irisData.target[i] for i in test] \n",
    "    testTargets.append(testingTargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing for each validation fold\n",
    "for i in range(0, k):\n",
    "    # Tree init\n",
    "    irisTree = tree.DecisionTreeClassifier()\n",
    "    \n",
    "    # Tree training\n",
    "    irisTree = irisTree.fit(trainSets[i], trainTargets[i])\n",
    "    \n",
    "    # Tree testing\n",
    "    testPredict = irisTree.predict(testSets[i])\n",
    "    \n",
    "    # Tree accuracy\n",
    "    accuracy = metrics.accuracy_score(testTargets[i], testPredict)\n",
    "    \n",
    "    # Recording accuracy score\n",
    "    allScores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9667\n",
      "Accuracy: 0.9667\n",
      "Accuracy: 0.9667\n",
      "Accuracy: 0.9333\n",
      "Accuracy: 0.8333\n",
      "\n",
      "Mean Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "for score in allScores:\n",
    "    print(\"Accuracy: {0:0.4f}\".format(score))\n",
    "# Summary of scores\n",
    "final = np.mean(allScores)\n",
    "print(\"\\nMean Accuracy: {0:0.4f}\".format(final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest Model with 5-fold Cross Validation</h1>\n",
    "\n",
    "Initial experimentation on Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lykas\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\lykas\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\lykas\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\lykas\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\lykas\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "forestScores = []\n",
    "\n",
    "# Training and Testing for each validation fold\n",
    "for i in range(0, k):\n",
    "    # Forest init\n",
    "    forest = ensemble.RandomForestClassifier()\n",
    "    \n",
    "    # Forest training\n",
    "    forest = forest.fit(trainSets[i], trainTargets[i])\n",
    "    \n",
    "    # Forest testing\n",
    "    testPredict = forest.predict(testSets[i])\n",
    "#     print(testPredict)\n",
    "    \n",
    "    # Forest accuracy\n",
    "    accuracy = metrics.accuracy_score(testTargets[i], testPredict)\n",
    "    \n",
    "    # Recording accuracy score\n",
    "    forestScores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9667\n",
      "Accuracy: 0.9667\n",
      "Accuracy: 0.9667\n",
      "Accuracy: 0.9333\n",
      "Accuracy: 0.9000\n",
      "\n",
      "Mean Accuracy: 0.9467\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "for score in forestScores:\n",
    "    print(\"Accuracy: {0:0.4f}\".format(score))\n",
    "# Summary of scores\n",
    "final = np.mean(forestScores)\n",
    "print(\"\\nMean Accuracy: {0:0.4f}\".format(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
