{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>RNN for Generating Text</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     2,
     34,
     43,
     60,
     73,
     77,
     98
    ]
   },
   "outputs": [],
   "source": [
    "class WriteForMe:\n",
    "    \n",
    "    def __init__(self, text, epochs=1, batchSize=50, seqLength=10, units=400, starter=\"\"):\n",
    "        '''\n",
    "        text: string of traning data\n",
    "        mapType: whether to map characters or words\n",
    "        \n",
    "        '''\n",
    "        self.batchSize = batchSize\n",
    "        self.epochs = epochs\n",
    "        self.text = text\n",
    "        \n",
    "        mapping = self.mapping()\n",
    "        self.nToKey = mapping[0]\n",
    "        self.keyToN = mapping[1]\n",
    "        \n",
    "        if len(starter) > 0:\n",
    "            print('starter given')\n",
    "            starter = self.encodeStr(starter)\n",
    "            self.seqLen = len(starter)\n",
    "            self.starter = starter\n",
    "        else:\n",
    "            self.seqLen = seqLength\n",
    "        \n",
    "        trainSet = self.preprocessing()\n",
    "        self.trainX = trainSet[0]\n",
    "        self.trainY = trainSet[1]\n",
    "        if len(starter) < 1:\n",
    "            print('default starter')\n",
    "            self.starter = trainSet[2]\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.modeling(units=units)\n",
    "\n",
    "    def mapping(self):\n",
    "        print('mapping')\n",
    "        \n",
    "        characters = sorted(list(set(self.text)))\n",
    "        self.chars = characters\n",
    "        nToChar = { n:char for n, char in enumerate(characters) }\n",
    "        charToN = { char:n for n, char in enumerate(characters) }\n",
    "        return [nToChar, charToN]\n",
    "\n",
    "    def preprocessing(self):\n",
    "        print('preprocessing')\n",
    "        \n",
    "        x = []\n",
    "        y = []\n",
    "        length = len(self.text)\n",
    "        for i in range(0, length-self.seqLen, 1):\n",
    "            sequence = self.text[i:i + self.seqLen]\n",
    "            label = self.text[i + self.seqLen]\n",
    "            x.append([self.keyToN[char] for char in sequence])\n",
    "            y.append(self.keyToN[label])\n",
    "            \n",
    "        xMod = np.reshape(x, (len(x), self.seqLen, 1))\n",
    "        xMod = xMod / float(len(self.keyToN))\n",
    "        yMod = np_utils.to_categorical(y)\n",
    "        return [xMod, yMod, x[self.seqLen-1]]\n",
    "    \n",
    "    def modeling(self, units):\n",
    "        print('modeling')\n",
    "        \n",
    "        self.model.add(LSTM(units, input_shape=(self.trainX.shape[1], self.trainX.shape[2]), return_sequences=True))\n",
    "        self.model.add(Dropout(0.2))\n",
    "        self.model.add(LSTM(units, return_sequences=True))\n",
    "        self.model.add(Dropout(0.2))\n",
    "        self.model.add(LSTM(units))\n",
    "        self.model.add(Dropout(0.2))\n",
    "        self.model.add(Dense(self.trainY.shape[1], activation='softmax'))\n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        \n",
    "    def fit(self):\n",
    "        print('fitting')\n",
    "        self.model.fit(self.trainX, self.trainY, epochs=self.epochs, batch_size=self.batchSize)\n",
    "        \n",
    "    def generateText(self, length=400):\n",
    "        mappedStr = self.starter\n",
    "        print('mapped', mappedStr)\n",
    "        fullStr = [self.nToKey[val] for val in mappedStr]\n",
    "        print(fullStr)\n",
    "        \n",
    "        for i in range(length):\n",
    "            x = np.reshape(mappedStr, (1, len(mappedStr), 1))\n",
    "            x = x / float(len(self.chars))\n",
    "            \n",
    "            nextPred = np.argmax(self.model.predict(x, verbose=0))\n",
    "            fullStr.append(self.nToKey[nextPred])\n",
    "            mappedStr.append(nextPred)\n",
    "            mappedStr = mappedStr[1:]\n",
    "            \n",
    "        print(fullStr)\n",
    "        final = \"\"\n",
    "        for char in fullStr:\n",
    "            final += char\n",
    "        print(final)\n",
    "        \n",
    "    def encodeStr(self, string):\n",
    "        print('encoding')\n",
    "        return [self.keyToN[char] for char in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486646 characters\n",
      "12166 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(\"data/emPosts.txt\", encoding=\"utf-8-sig\").read()\n",
    "text = text.lower()\n",
    "print(len(text), 'characters')\n",
    "\n",
    "# Portioning text for faster testsing\n",
    "cut = int(len(text) / 40)\n",
    "print(cut, 'characters')\n",
    "text = text[:cut]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping\n",
      "preprocessing\n",
      "default starter\n",
      "modeling\n"
     ]
    }
   ],
   "source": [
    "test01 = WriteForMe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting\n",
      "Epoch 1/1\n",
      "12156/12156 [==============================] - 35s 3ms/step - loss: 3.0045\n"
     ]
    }
   ],
   "source": [
    "test01.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped [1, 13, 30, 30, 1, 12, 18, 16, 1, 9]\n",
      "[' ', 'b', 's', 's', ' ', 'a', 'g', 'e', ' ', '2']\n",
      "[' ', 'b', 's', 's', ' ', 'a', 'g', 'e', ' ', '2', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
      " bss age 2                                                                                                                                                                                                                                                                                                                                                                                                                \n"
     ]
    }
   ],
   "source": [
    "test01.generateText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
