{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Various Analyses</h1>\n",
    "\n",
    "Trying different analyses on Decision Trees, Random Forests, and K-Fold Cross Validation through changing of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cc10adb3f67a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;31m# GH 27101\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;31m# TODO: remove Panel compat in 1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY37\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'compat'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris # Iris dataset\n",
    "from sklearn.model_selection import KFold # K-fold Cross Validation\n",
    "from sklearn import tree # Decision Tree\n",
    "from sklearn import ensemble # Random forest\n",
    "from sklearn import metrics # Accuracy scores\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Helper Functions</h2>\n",
    "\n",
    "Function for obtaining data splits over k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSets(k, data, targets):\n",
    "    kFold = KFold(k, True, 1)\n",
    "\n",
    "    # Data sets\n",
    "    trainSets = []\n",
    "    testSets = []\n",
    "    # Target sets\n",
    "    trainTargs = []\n",
    "    testTargs = []\n",
    "    \n",
    "    for train, test in kFold.split(data):\n",
    "        # Training values\n",
    "        trainSets.append( [data[i] for i in train] )\n",
    "        trainTargs.append( [targets[i] for i in train] )\n",
    "\n",
    "        # Testing values\n",
    "        testSets.append( [data[i] for i in test] )\n",
    "        testTargs.append( [targets[i] for i in test] )\n",
    "        \n",
    "    return trainSets, testSets, trainTargs, testTargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for printing out accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printScores(scores):\n",
    "    # Results\n",
    "    for score in scores:\n",
    "        print(\"Accuracy: {0:0.4f}\".format(score))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for plotting results / scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSingleScore(scores, xL, yL, t):\n",
    "    n = len(scores)\n",
    "    x = np.linspace(0, n, num = n)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    p1 = fig.add_subplot()\n",
    "    # It's the holidays\n",
    "    p1.plot(x, scores,\n",
    "             color = \"forestgreen\",\n",
    "             marker = \"*\",\n",
    "             markersize = \"10\",\n",
    "             markeredgecolor = \"indianred\",\n",
    "             markerfacecolor = \"indianred\",)\n",
    "    \n",
    "    p1.set_xlabel(xL)\n",
    "    p1.set_ylabel(yL)\n",
    "    p1.set_title(t)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotModelPerformance(df, xL):\n",
    "    n = df.shape[0]\n",
    "    x = np.linspace(0, n, num = n)\n",
    "    \n",
    "    fig, p = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    plots = {\n",
    "        \"accuracy\": {\n",
    "            \"index\": [0, 0],\n",
    "            \"yLabel\": \"Mean Accuracy\",\n",
    "            \"color\": \"tomato\"\n",
    "        },\n",
    "        \"bias\": {\n",
    "            \"index\": [0, 1],\n",
    "            \"yLabel\": \"Mean Bias\",\n",
    "            \"color\": \"orange\"\n",
    "        },\n",
    "        \"variance\": {\n",
    "            \"index\": [1, 0],\n",
    "            \"yLabel\": \"Mean Varianve\",\n",
    "            \"color\": \"limegreen\"\n",
    "        },\n",
    "        \"mse\": {\n",
    "            \"index\": [1, 1],\n",
    "            \"yLabel\": \"Mean Square Errror\",\n",
    "            \"color\": \"cornflowerblue\"\n",
    "        },\n",
    "    }\n",
    "    for column in df:\n",
    "        currData = plots[column]\n",
    "        index = currData[\"index\"]\n",
    "        p[index[0], index[1]].plot(x, column, data=df,\n",
    "               color = currData[\"color\"])\n",
    "        p[index[0], index[1]].set_xlabel(xL)\n",
    "        p[index[0], index[1]].set_ylabel(currData[\"yLabel\"])\n",
    "    \n",
    "    print()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for finding Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVariance(predictions):\n",
    "    return np.mean((predictions - np.mean(predictions))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for finding Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBias(predictions, target):\n",
    "    truth = np.mean(target)\n",
    "    return np.mean(predictions) - truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for finding Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMSE(predictions, target):\n",
    "    truth = np.mean(target)\n",
    "    return np.mean((predictions-truth)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris Dataset\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-33a15d08c2bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Wine Quality Dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'WineQuality/winequality-white.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'quality'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Wine Quality Dataset\n",
    "df = pd.read_csv('WineQuality/winequality-white.csv', delimiter=';')\n",
    "\n",
    "wines = df.drop(columns='quality')\n",
    "wines = wines.to_numpy()\n",
    "\n",
    "targets = df['quality']\n",
    "targets = targets.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Trees</h1>\n",
    "\n",
    "Analysis on how the maximum depth (`max_depth`) of a tree affects model accuracy and execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run a Decision Tree with max_depth n over k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDecisionTree(k, data, targets, n):\n",
    "    accuracy = []\n",
    "    squareErrors = []\n",
    "    variances = []\n",
    "    biases= []\n",
    "    trainS, testS, trainT, testT = getSets(k, data, targets)\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        classTree = tree.DecisionTreeClassifier(max_depth = n)\n",
    "        # Training\n",
    "        classTree = classTree.fit(trainS[i], trainT[i])\n",
    "        # Testing\n",
    "        test = classTree.predict(testS[i])\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy.append(metrics.accuracy_score(testT[i], test))\n",
    "        # Variances\n",
    "        variances.append(getVariance(test))\n",
    "        # Biases\n",
    "        biases.append(getBias(test, testT[i]))\n",
    "        # Mean Square Error\n",
    "        squareErrors.append(getMSE(test, testT[i]))\n",
    "        \n",
    "    # Mean results\n",
    "    data = {\n",
    "        \"accuracy\": np.mean(accuracy),\n",
    "        \"bias\": np.mean(biases),\n",
    "        \"variance\": np.mean(variances),\n",
    "        \"mse\": np.mean(squareErrors)\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run decision trees with max_depths within the range (start, end), over k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTreeDepths(k, start, end, data, targets):\n",
    "    allData = []\n",
    "    for i in range(start, end):\n",
    "        allData.append(runDecisionTree(k, data, targets, i))\n",
    "    \n",
    "    return pd.DataFrame(allData)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Iris Flowers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decision Trees with max depths 1-10 at 5-folds\n",
    "result = runTreeDepths(5, 1, 10, iris.data, iris.target)\n",
    "\n",
    "# Plot labels\n",
    "xAxis = \"Max Depth\"\n",
    "plotModelPerformance(result, xAxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Wine Quality</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees with max depths 1-10 at 5-folds\n",
    "result = runTreeDepths(5, 1, 10, wines, targets)\n",
    "\n",
    "# Plot labels\n",
    "xAxis = \"Max Depth\"\n",
    "plotModelPerformance(result, xAxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>\n",
    "\n",
    "Analysis on how the number of trees (`n_estimators`) in a forest effects model accuracy and execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run a Random Forest over k-folds with n trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runRandomForest(k, n, data, targets, d):\n",
    "    accuracy = []\n",
    "    squareErrors = []\n",
    "    variances = []\n",
    "    biases= []\n",
    "    trainS, testS, trainT, testT = getSets(k, data, targets)\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        forest = ensemble.RandomForestClassifier(n_estimators = n, max_depth = d)\n",
    "        # Training\n",
    "        forest = forest.fit(trainS[i], trainT[i])\n",
    "        # Testing\n",
    "        test = forest.predict(testS[i])\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy.append(metrics.accuracy_score(testT[i], test))\n",
    "        # Variances\n",
    "        variances.append(getVariance(test))\n",
    "        # Biases\n",
    "        biases.append(getBias(test, testT[i]))\n",
    "        # Mean Square Error\n",
    "        squareErrors.append(getMSE(test, testT[i]))\n",
    "        \n",
    "    # Mean results\n",
    "    data = {\n",
    "        \"accuracy\": np.mean(accuracy),\n",
    "        \"bias\": np.mean(biases),\n",
    "        \"variance\": np.mean(variances),\n",
    "        \"mse\": np.mean(squareErrors)\n",
    "    }\n",
    "    \n",
    "    # Printing results\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run Random Forests of range(start, end) trees with max_depth d over k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runForestNums(k, start, end, data, targets, d):\n",
    "    allData = []\n",
    "    for i in range(start, end):\n",
    "        allData.append(runRandomForest(k, i, data, targets, d))\n",
    "        \n",
    "    return pd.DataFrame(allData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Iris Flowers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with trees of max depth 5 and 10-20 trees\n",
    "result = runForestNums(5, 10, 20, iris.data, iris.target, 5)\n",
    "\n",
    "# Plot labels\n",
    "xAxis = \"Max Depth\"\n",
    "plotModelPerformance(result, xAxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Wine Quality</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with trees of max depth 5 and 10-20 trees\n",
    "result = runForestNums(5, 10, 20, wines, targets, 5)\n",
    "\n",
    "# Plot labels\n",
    "xAxis = \"Max Depth\"\n",
    "plotModelPerformance(result, xAxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K-Fold Cross Validation</h1>\n",
    "\n",
    "Analysis on how number of folds (`k`) affects the validation of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Iris Flowers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Wine Quality</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
